---
title: "MIS 510 Portfolio Project Option 1"
author: "Cody Mitchell"
date: "9/3/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Setting Up the Libraries and Data
## Loading in Necessary Libraries
```{r}
#loading in libraries
library(gains)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
```

## Loading and Preparing the Dataset
```{r}
#loading the data set
Credit <- read.csv("GermanCredit (1).csv")

#remove first row from data since obsolete
Credit<-Credit[,-1]

#factoring the variables so correctly interpredited
Credit$CHK_ACCT <- factor(Credit$CHK_ACCT)
Credit$HISTORY <- factor(Credit$HISTORY)
Credit$SAV_ACCT <- factor(Credit$SAV_ACCT)
Credit$EMPLOYMENT <- factor(Credit$EMPLOYMENT)
Credit$PRESENT_RESIDENT <- factor(Credit$PRESENT_RESIDENT)
Credit$JOB <- factor(Credit$JOB)

#Opportunity of cost matrix 
cost.matrix<- matrix(c(0,500,100,0),2,2,byrow=TRUE)
colnames(cost.matrix)<-row.names(cost.matrix)<- c("Good", "Bad")
cost.matrix

#average net profit matrix 
net.profit.matrix<- matrix(c(100,-500,0,0),2,2,byrow = TRUE)
colnames(net.profit.matrix)<-row.names(net.profit.matrix)<- c("Good", "Bad")
net.profit.matrix
```
# Exploring and Partitioning the Data
## Exploratory Functions on Credit Data
```{r}
#Finding the total entries
length(Credit$RESPONSE)
#good versus basd credit counts
summary(Credit$RESPONSE)
#average age of member
mean(Credit$AGE)
#minimum age of member
min(Credit$AGE)
#na values in data
any(is.na(Credit))
#see how response variable classified
class(Credit$RESPONSE)
```

## Partitioning the Dataset
```{r}
#setting seed for reproducability
set.seed(1)
#creating the training index rows
train.index<- sample(c(1:dim(Credit)[1]), dim(Credit)[1]*0.6)
#creating training and validation dataframes
train.df<-Credit[train.index,]
valid.df<- Credit[-train.index,]
```

# Logistic Regression Model
## Creating the Model
```{r}
#making the regression
logit.reg<- glm(RESPONSE ~ ., data = train.df, family = "binomial")
options(scipen = 999)
summary(logit.reg)
```

## Predicting with the Model
```{r}
#use predict() with type = "response" to compute predicted probabilities
logit.reg.pred<- predict(logit.reg, valid.df[,-31], type = "response")

#first 5 actual and predicted records
data.frame(actual = valid.df$RESPONSE[1:5], predicted = logit.reg.pred[1:5])
```

## Graphics for Linear Model
```{r}
#Creating a ROC chart for logistic model
#will help us choose different cutoff values for the confusion matrix
ROC<-roc(valid.df$RESPONSE, logit.reg.pred)
plot.roc(ROC, main = "ROC for Logistic Model")

#compute auc
auc(ROC)

#Making a lift chart for logistic model
#will show how our model compares to random guess
gain<- gains(valid.df$RESPONSE, logit.reg.pred, groups = 10)
plot(c(0,gain$cume.pct.of.total*sum(valid.df$RESPONSE))~ c(0,gain$cume.obs), xlab="# Cases", ylab = "Cumulative", main = "Gain Chart for Logistic Model", type = "l")
lines(c(0, sum(valid.df$RESPONSE))~ c(0, dim(valid.df)[1]), lty =2)
```

# Matrices for Logistic Models
```{r}
#confusion matrix for logistic model with 0.5 Cutoff
log.conf.5<-confusionMatrix(as.factor(ifelse(logit.reg.pred > 0.5, 1, 0)), as.factor(valid.df$RESPONSE))
log.conf.5

#Confusion Matrix for logistic model with 0.35 cutoff
#Based off of ROC chart and the net profit from book
log.conf.35<-confusionMatrix(as.factor(ifelse(logit.reg.pred > 0.35, 1, 0)), as.factor(valid.df$RESPONSE))
log.conf.35

```

# Classification Tree
```{r}
#use rpart to run a classification tree
#define rpart.control() in rpart() to determine depth of tree
class.tree<- rpart(RESPONSE ~ ., data = train.df, method = "class", cp = 0, minsplit = 10)

#plotting the classification tree
prp(class.tree, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10, box.col = ifelse(class.tree$frame$var == "<leaf>", 'gray', 'white'))

#count leaves
length(class.tree$frame$var[class.tree$frame$var == '<leaf>'])

###Second Classification Tree with cross validation and pruning lower cp
#argument xval refers to number of folds to use in cross validation
class.tree2<- rpart(RESPONSE ~.,data = train.df, method = "class",minsplit = 5, xval = 5)

#prune by lower cp
pruned.ct<- prune(class.tree2, cp = class.tree2$cptable[which.min(class.tree2$cptable[, "xerror"]),"CP"])
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>'"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10)

```

# Confusion Matrices for Classification Tree Models
```{r}
#confusion matrix for the classification tree on training set
class.tree.point.pred.train<- predict(class.tree, train.df, type = "class")
confusionMatrix(class.tree.point.pred.train, as.factor(train.df$RESPONSE))

#confusion matrix for the classification tree on validation set
class.tree.point.pred.valid <- predict(class.tree, valid.df, type = "class")
tree.conf<-confusionMatrix(class.tree.point.pred.valid, as.factor(valid.df$RESPONSE))
tree.conf


#confusion matrix for pruned tree on training data
prune.tree.point.pred.train <- predict(pruned.ct, train.df, type = "class")
confusionMatrix(prune.tree.point.pred.train, as.factor(train.df$RESPONSE))

#confusion matrix for pruned tree on validation data
prune.tree.point.pred.valid <- predict(pruned.ct, valid.df, type = "class")
tree.conf.prune<- confusionMatrix(prune.tree.point.pred.valid, as.factor(valid.df$RESPONSE))
tree.conf.prune
```
# Comparing Costs of Models
## Opportunity of Cost Matrices
```{r}
#opportunity of cost matrix for the logistical modelat 0.5 cutoff
cost.matrix.log<-cost.matrix*log.conf.5$table
cost.matrix.log

#opportunity of cost matrix for the logistical model at 0.35 cutoff
cost.matrix.log.35<-cost.matrix*log.conf.35$table
cost.matrix.log.35

#opportunity of cost matrix for classification tree model
cost.matrix.tree<-cost.matrix*tree.conf$table
cost.matrix.tree

#opportunity of cost matrix for pruned classification tree model
cost.matrix.tree.prune<-cost.matrix*tree.conf.prune$table
cost.matrix.tree.prune
```

## Average Net Profit Matrix
```{r}
#average net profit matrix for the logistical model at 0.5 cutoff
net.profit.matrix.log<-net.profit.matrix*log.conf.5$table
net.profit.matrix.log

#average net profit matrix for the logistical model at .35 cutoff
net.profit.matrix.log.35<-net.profit.matrix*log.conf.35$table
net.profit.matrix.log.35

#average net profit matrix for the tree classification model
net.profit.matrix.class<-net.profit.matrix*tree.conf$table
net.profit.matrix.class

#average net profit matrix for pruned tree classification model
net.profit.matrix.class.prune<-net.profit.matrix*tree.conf.prune$table
net.profit.matrix.class.prune
```

## Comparing the Models
```{r}
##Comparing the associated opportunity costs of the models
#log model with 0.5 cutoff
sum(cost.matrix.log)
#log model with 0.35 cutoff
sum(cost.matrix.log.35)
#tree classification model
sum(cost.matrix.tree)
#pruned tree model
sum(cost.matrix.tree.prune)

##Comparing the Net Profit of the models
#logistic model with 0.5 cutoff
sum(net.profit.matrix.log)
#logistic model with 0.35 cutoff
sum(net.profit.matrix.log.35)
#classification tree model
sum(net.profit.matrix.class)
#pruned classification tree model
sum(net.profit.matrix.class.prune)
```
